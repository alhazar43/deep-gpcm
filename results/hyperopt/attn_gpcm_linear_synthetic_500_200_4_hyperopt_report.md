# Hyperparameter Optimization Report

**Model:** attn_gpcm_linear  
**Dataset:** synthetic_500_200_4  
**Generated:** 2025-08-15 11:34:22  

## Summary

- **Total Trials:** 20
- **Successful Trials:** 20 (100.0%)
- **Best Score:** 0.5854
- **Mean Score:** 0.3540 ¬± 0.2261
- **Total Time:** 10191.3s
- **Convergence Trial:** 5

## Best Parameters

- **memory_size:** 50
- **final_fc_dim:** 50
- **dropout_rate:** 0.193917
- **embed_dim:** 64
- **n_heads:** 4
- **n_cycles:** 2
- **ce_weight_logit:** 1.579309
- **focal_weight_logit:** 0.391600
- **key_dim:** 128
- **value_dim:** 256
- **lr:** 0.000976
- **weight_decay:** 0.000197
- **batch_size:** 32
- **grad_clip:** 4.825274
- **label_smoothing:** 0.168907

## Parameter Importance

- **lr:** 47.2%
- **ce_weight_logit:** 13.2%
- **batch_size:** 11.9%
- **grad_clip:** 8.2%
- **key_dim:** 6.9%
- **dropout_rate:** 4.5%
- **focal_weight_logit:** 4.0%
- **weight_decay:** 1.2%
- **final_fc_dim:** 1.1%
- **memory_size:** 0.7%
- **label_smoothing:** 0.4%
- **embed_dim:** 0.3%
- **value_dim:** 0.3%
- **n_cycles:** 0.1%
- **n_heads:** 0.1%

## Parameter-Performance Correlations

- **key_dim:** 0.917
- **lr:** -0.847
- **final_fc_dim:** -0.827
- **ce_weight_logit:** 0.804
- **grad_clip:** 0.765
- **batch_size:** -0.756
- **focal_weight_logit:** 0.731
- **dropout_rate:** 0.714
- **label_smoothing:** 0.547
- **value_dim:** -0.357
- **memory_size:** 0.266
- **n_cycles:** 0.217
- **weight_decay:** -0.201
- **embed_dim:** -0.158
- **n_heads:** -0.071

## Convergence Analysis

- **Convergence Trial:** 5
- **Final Best Score:** 0.5854
- **Improvement Rate:** 0.0214
- **Convergence Efficiency:** 25.0%

## Optimization Efficiency

- **Score Range:** 0.5795
- **Exploration Ratio:** 0.380
- **Improvement Rate:** 0.2036
- **95th Percentile Score:** 0.5493

## ü§ñ Automated Analysis & Recommendations

*This section provides AI-generated insights and actionable recommendations based on the optimization results.*

### üìä Performance Summary

- Best performance: 0.5854 QWK (Trial #5)
- Performance range: 0.5795 spread across all trials
- Convergence efficiency: Good (25.0% of trials needed)

### üîç Parameter Patterns

- Lower final_fc_dim values strongly improve performance (correlation: -0.827)
- Lower lr values strongly improve performance (correlation: -0.847)
- Lower batch_size values strongly improve performance (correlation: -0.756)
- Higher dropout_rate values strongly improve performance (correlation: 0.714)
- Higher ce_weight_logit values strongly improve performance (correlation: 0.804)
- Higher focal_weight_logit values strongly improve performance (correlation: 0.731)
- Higher key_dim values strongly improve performance (correlation: 0.917)
- Higher grad_clip values strongly improve performance (correlation: 0.765)
- Higher label_smoothing values strongly improve performance (correlation: 0.547)

### ‚öñÔ∏è Loss Function Insights

- Optimal loss combination: CE=0.66, Focal=0.20, QWK=0.14

### üöÄ Actionable Recommendations

- Efficient convergence - current search space and strategy are effective
- Higher regularization needed - current dropout level is appropriate

### üìã Next Steps

- Performance below 65% QWK - expand architectural parameters and increase trial budget
- Implement adaptive epoch allocation (5‚Üí20‚Üí40 epochs based on performance)
- Add learning rate scheduling and optimizer parameters to search space
- Consider increasing trial budget for more thorough exploration

## Visualizations

- **Main Analysis:** `results/hyperopt/attn_gpcm_linear_synthetic_500_200_4_hyperopt_analysis.png`
- **Detailed Parameters:** `results/hyperopt/attn_gpcm_linear_synthetic_500_200_4_detailed_parameters.png`

---
*Generated by Deep-GPCM Hyperparameter Optimization System*
