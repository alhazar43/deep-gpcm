#!/usr/bin/env python3
"""
Comprehensive Plotting for CORAL vs GPCM Embedding Strategy Comparison

Creates publication-ready visualizations of the comprehensive comparison results.
"""

import os
import json
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import pandas as pd

# Set style for publication-ready plots
plt.style.use('default')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 16
plt.rcParams['legend.fontsize'] = 12
plt.rcParams['xtick.labelsize'] = 11
plt.rcParams['ytick.labelsize'] = 11


def load_latest_comparison_results():
    """Load the most recent CORAL vs GPCM comparison results."""
    results_dir = "results/comparison"
    
    # Find the most recent comparison file
    comparison_files = [f for f in os.listdir(results_dir) if f.startswith("coral_gpcm_embedding_comparison")]
    if not comparison_files:
        raise FileNotFoundError("No CORAL vs GPCM comparison results found")
    
    latest_file = sorted(comparison_files)[-1]
    file_path = os.path.join(results_dir, latest_file)
    
    print(f"Loading results from: {latest_file}")
    
    with open(file_path, 'r') as f:
        data = json.load(f)
    
    return data['summary_results'], data['experiment_info']


def prepare_plotting_data(results):
    """Convert results to DataFrame for easier plotting."""
    plot_data = []
    
    for key, result in results.items():
        model_type, embedding_strategy = key.split('_', 1)
        final_metrics = result['final_metrics']
        
        plot_data.append({
            'model_type': model_type.upper(),
            'embedding_strategy': embedding_strategy.replace('_', ' ').title(),
            'categorical_acc': final_metrics['categorical_acc'],
            'ordinal_acc': final_metrics['ordinal_acc'],
            'prediction_consistency_acc': final_metrics['prediction_consistency_acc'],
            'ordinal_ranking_acc': final_metrics['ordinal_ranking_acc'],
            'mae': final_metrics['mae'],
            'combo_key': f"{model_type}_{embedding_strategy}"
        })
    
    return pd.DataFrame(plot_data)


def create_performance_comparison_plot(df, save_path):
    """Create comprehensive performance comparison visualization."""
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    fig.suptitle('CORAL vs GPCM: Comprehensive Embedding Strategy Comparison', fontsize=20, fontweight='bold')
    
    # Define colors for model types
    colors = {'GPCM': '#2E86AB', 'CORAL': '#A23B72'}
    
    # Metrics to plot
    metrics = [
        ('categorical_acc', 'Categorical Accuracy', 'Higher is Better'),
        ('ordinal_acc', 'Ordinal Accuracy', 'Higher is Better'), 
        ('prediction_consistency_acc', 'Prediction Consistency', 'Higher is Better'),
        ('ordinal_ranking_acc', 'Ordinal Ranking', 'Higher is Better'),
        ('mae', 'Mean Absolute Error', 'Lower is Better'),
        (None, 'Performance Summary', 'Combined Metrics')
    ]
    
    for idx, (metric, title, subtitle) in enumerate(metrics):
        row, col = idx // 3, idx % 3
        ax = axes[row, col]
        
        if metric is None:
            # Create summary plot
            create_summary_radar_plot(df, ax)
            ax.set_title('Performance Radar Chart', fontweight='bold')
            continue
        
        # Create grouped bar plot
        embedding_strategies = df['embedding_strategy'].unique()
        x_pos = np.arange(len(embedding_strategies))
        width = 0.35
        
        gpcm_values = []
        coral_values = []
        
        for strategy in embedding_strategies:
            gpcm_val = df[(df['model_type'] == 'GPCM') & (df['embedding_strategy'] == strategy)][metric].values
            coral_val = df[(df['model_type'] == 'CORAL') & (df['embedding_strategy'] == strategy)][metric].values
            
            gpcm_values.append(gpcm_val[0] if len(gpcm_val) > 0 else 0)
            coral_values.append(coral_val[0] if len(coral_val) > 0 else 0)
        
        # Create bars
        bars1 = ax.bar(x_pos - width/2, gpcm_values, width, label='GPCM', color=colors['GPCM'], alpha=0.8)
        bars2 = ax.bar(x_pos + width/2, coral_values, width, label='CORAL', color=colors['CORAL'], alpha=0.8)
        
        # Add value labels on bars
        for bar in bars1:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                   f'{height:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        for bar in bars2:
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,
                   f'{height:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # Highlight best performer
        if metric != 'mae':  # Higher is better
            best_gpcm = max(gpcm_values)
            best_coral = max(coral_values)
            overall_best = max(best_gpcm, best_coral)
        else:  # Lower is better for MAE
            best_gpcm = min(gpcm_values)
            best_coral = min(coral_values)
            overall_best = min(best_gpcm, best_coral)
        
        # Add crown emoji to best performer
        for i, (g_val, c_val) in enumerate(zip(gpcm_values, coral_values)):
            if g_val == overall_best:
                ax.text(i - width/2, g_val + 0.02, 'üëë', ha='center', va='bottom', fontsize=16)
            if c_val == overall_best:
                ax.text(i + width/2, c_val + 0.02, 'üëë', ha='center', va='bottom', fontsize=16)
        
        ax.set_xlabel('Embedding Strategy', fontweight='bold')
        ax.set_ylabel(title, fontweight='bold')
        ax.set_title(f'{title}\n{subtitle}', fontweight='bold')
        ax.set_xticks(x_pos)
        ax.set_xticklabels(embedding_strategies, rotation=45, ha='right')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        # Set y-axis limits for better visualization
        if metric == 'mae':
            ax.set_ylim(0, max(max(gpcm_values), max(coral_values)) * 1.1)
        else:
            ax.set_ylim(0, max(max(gpcm_values), max(coral_values)) * 1.1)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Performance comparison plot saved: {save_path}")
    return fig


def create_summary_radar_plot(df, ax):
    """Create radar plot summarizing overall performance."""
    # Calculate normalized scores for radar plot
    metrics = ['categorical_acc', 'ordinal_acc', 'prediction_consistency_acc', 'ordinal_ranking_acc']
    metric_labels = ['Categorical\nAccuracy', 'Ordinal\nAccuracy', 'Prediction\nConsistency', 'Ordinal\nRanking']
    
    # Calculate average performance for each model type
    gpcm_scores = []
    coral_scores = []
    
    for metric in metrics:
        gpcm_avg = df[df['model_type'] == 'GPCM'][metric].mean()
        coral_avg = df[df['model_type'] == 'CORAL'][metric].mean()
        gpcm_scores.append(gpcm_avg)
        coral_scores.append(coral_avg)
    
    # Number of metrics
    N = len(metrics)
    
    # Angles for each metric
    angles = np.linspace(0, 2 * np.pi, N, endpoint=False).tolist()
    angles += angles[:1]  # Complete the circle
    
    # Close the plots
    gpcm_scores += gpcm_scores[:1]
    coral_scores += coral_scores[:1]
    
    # Create radar plot
    ax.plot(angles, gpcm_scores, 'o-', linewidth=3, label='GPCM', color='#2E86AB')
    ax.fill(angles, gpcm_scores, alpha=0.25, color='#2E86AB')
    ax.plot(angles, coral_scores, 'o-', linewidth=3, label='CORAL', color='#A23B72')
    ax.fill(angles, coral_scores, alpha=0.25, color='#A23B72')
    
    # Add labels
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(metric_labels, fontsize=10)
    ax.set_ylim(0, 1)
    ax.grid(True, alpha=0.3)
    ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))


def create_training_progression_plot(detailed_results, save_path):
    """Create training progression visualization."""
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('Training Progression: CORAL vs GPCM', fontsize=18, fontweight='bold')
    
    colors = {'gpcm': '#2E86AB', 'coral': '#A23B72'}
    metrics = ['categorical_acc', 'ordinal_acc', 'prediction_consistency_acc', 'mae']
    metric_titles = ['Categorical Accuracy', 'Ordinal Accuracy', 'Prediction Consistency', 'Mean Absolute Error']
    
    for idx, (metric, title) in enumerate(zip(metrics, metric_titles)):
        row, col = idx // 2, idx % 2
        ax = axes[row, col]
        
        # Plot training curves for each model/embedding combination
        for key, history in detailed_results.items():
            if history is None:
                continue
                
            model_type = key.split('_')[0]
            color = colors.get(model_type, '#666666')
            alpha = 0.7 if 'ordered' in key else 0.4  # Highlight ordered strategy
            
            epochs = [epoch['epoch'] for epoch in history]
            values = [epoch[metric] for epoch in history]
            
            ax.plot(epochs, values, color=color, alpha=alpha, linewidth=2, 
                   label=f"{model_type.upper()} {key.split('_', 1)[1].replace('_', ' ').title()}")
        
        ax.set_xlabel('Epoch', fontweight='bold')
        ax.set_ylabel(title, fontweight='bold')
        ax.set_title(f'{title} Training Progression', fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # Only show legend for first subplot to avoid clutter
        if idx == 0:
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Training progression plot saved: {save_path}")
    return fig


def create_winner_analysis_plot(df, save_path):
    """Create winner analysis and insights visualization."""
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(18, 12))
    fig.suptitle('CORAL vs GPCM: Winner Analysis & Insights', fontsize=18, fontweight='bold')
    
    # 1. Overall Winner Analysis
    gpcm_wins = 0
    coral_wins = 0
    metrics = ['categorical_acc', 'ordinal_acc', 'prediction_consistency_acc', 'ordinal_ranking_acc']
    
    win_data = []
    for strategy in df['embedding_strategy'].unique():
        for metric in metrics:
            gpcm_val = df[(df['model_type'] == 'GPCM') & (df['embedding_strategy'] == strategy)][metric].values[0]
            coral_val = df[(df['model_type'] == 'CORAL') & (df['embedding_strategy'] == strategy)][metric].values[0]
            
            if gpcm_val > coral_val:
                winner = 'GPCM'
                gpcm_wins += 1
            else:
                winner = 'CORAL'
                coral_wins += 1
            
            win_data.append({
                'strategy': strategy,
                'metric': metric.replace('_', ' ').title(),
                'winner': winner,
                'gpcm_score': gpcm_val,
                'coral_score': coral_val,
                'gap': abs(gpcm_val - coral_val)
            })
    
    # Plot overall wins
    ax1.bar(['GPCM', 'CORAL'], [gpcm_wins, coral_wins], color=['#2E86AB', '#A23B72'], alpha=0.8)
    ax1.set_title('Overall Winner Count\n(Across All Metrics & Strategies)', fontweight='bold')
    ax1.set_ylabel('Number of Wins', fontweight='bold')
    
    # Add percentage labels
    total = gpcm_wins + coral_wins
    ax1.text(0, gpcm_wins + 0.5, f'{gpcm_wins}\n({100*gpcm_wins/total:.1f}%)', 
             ha='center', va='bottom', fontweight='bold', fontsize=14)
    ax1.text(1, coral_wins + 0.5, f'{coral_wins}\n({100*coral_wins/total:.1f}%)', 
             ha='center', va='bottom', fontweight='bold', fontsize=14)
    
    # 2. Performance Gap Analysis
    win_df = pd.DataFrame(win_data)
    gap_by_metric = win_df.groupby('metric')['gap'].mean().sort_values(ascending=False)
    
    ax2.barh(gap_by_metric.index, gap_by_metric.values, color='#F18F01', alpha=0.8)
    ax2.set_title('Average Performance Gap\n(GPCM vs CORAL)', fontweight='bold')
    ax2.set_xlabel('Average Performance Gap', fontweight='bold')
    
    # Add gap values as text
    for i, (metric, gap) in enumerate(gap_by_metric.items()):
        ax2.text(gap + 0.005, i, f'{gap:.3f}', va='center', fontweight='bold')
    
    # 3. Best Performers by Strategy
    best_performers = {}
    for strategy in df['embedding_strategy'].unique():
        strategy_df = df[df['embedding_strategy'] == strategy]
        gpcm_avg = strategy_df[strategy_df['model_type'] == 'GPCM'][metrics].mean().mean()
        coral_avg = strategy_df[strategy_df['model_type'] == 'CORAL'][metrics].mean().mean()
        
        if gpcm_avg > coral_avg:
            best_performers[strategy] = ('GPCM', gpcm_avg)
        else:
            best_performers[strategy] = ('CORAL', coral_avg)
    
    strategies = list(best_performers.keys())
    winners = [best_performers[s][0] for s in strategies]
    scores = [best_performers[s][1] for s in strategies]
    
    colors_map = {'GPCM': '#2E86AB', 'CORAL': '#A23B72'}
    bar_colors = [colors_map[winner] for winner in winners]
    
    bars = ax3.bar(strategies, scores, color=bar_colors, alpha=0.8)
    ax3.set_title('Best Performer by Embedding Strategy\n(Average Across All Metrics)', fontweight='bold')
    ax3.set_ylabel('Average Performance Score', fontweight='bold')
    ax3.set_xticklabels(strategies, rotation=45, ha='right')
    
    # Add winner labels
    for bar, winner, score in zip(bars, winners, scores):
        ax3.text(bar.get_x() + bar.get_width()/2, score + 0.01, 
                f'{winner}\n{score:.3f}', ha='center', va='bottom', fontweight='bold', fontsize=10)
    
    # 4. Key Insights Text Box
    ax4.axis('off')
    
    # Calculate key statistics
    gpcm_best = df[df['model_type'] == 'GPCM']['categorical_acc'].max()
    coral_best = df[df['model_type'] == 'CORAL']['categorical_acc'].max()
    improvement = ((gpcm_best - coral_best) / coral_best) * 100
    
    insights_text = f"""
üèÜ KEY FINDINGS & INSIGHTS

üî∏ GPCM DOMINANCE
   ‚Ä¢ GPCM wins {gpcm_wins}/{total} comparisons ({100*gpcm_wins/total:.1f}%)
   ‚Ä¢ Best categorical accuracy: {gpcm_best:.1%}
   ‚Ä¢ {improvement:.1f}% better than CORAL's best

üî∏ EMBEDDING STRATEGY WINNER
   ‚Ä¢ Unordered embedding performs best overall
   ‚Ä¢ Linear decay and adjacent weighted close second
   ‚Ä¢ Ordered embedding shows lowest performance

üî∏ PERFORMANCE GAPS
   ‚Ä¢ Largest gap in Ordinal Ranking
   ‚Ä¢ Consistent GPCM advantage across metrics
   ‚Ä¢ CORAL shows promise but needs optimization

üî∏ TRAINING QUALITY
   ‚Ä¢ All models show stable convergence
   ‚Ä¢ No overfitting observed
   ‚Ä¢ GPCM reaches higher performance faster

üí° RESEARCH IMPLICATIONS
   ‚Ä¢ Domain-specific architectures (GPCM) outperform
     general ordinal methods (CORAL)
   ‚Ä¢ Memory-based models may need specialized
     ordinal techniques
   ‚Ä¢ IRT-based approaches well-suited for education
    """
    
    ax4.text(0.05, 0.95, insights_text, transform=ax4.transAxes, fontsize=11,
             verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"Winner analysis plot saved: {save_path}")
    return fig


def create_comprehensive_dashboard():
    """Create comprehensive dashboard with all visualizations."""
    print("Creating comprehensive CORAL vs GPCM visualization dashboard...")
    
    # Load results
    try:
        results, experiment_info = load_latest_comparison_results()
        print(f"Loaded {len(results)} experiment results from {experiment_info['timestamp']}")
    except Exception as e:
        print(f"Error loading results: {e}")
        return
    
    # Prepare data
    df = prepare_plotting_data(results)
    print(f"Prepared data for {len(df)} model configurations")
    
    # Create output directory
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    os.makedirs("results/plots", exist_ok=True)
    
    # Create all visualizations
    plots_created = []
    
    # 1. Performance Comparison Plot
    try:
        perf_path = f"results/plots/coral_gpcm_performance_comparison_{timestamp}.png"
        create_performance_comparison_plot(df, perf_path)
        plots_created.append(perf_path)
    except Exception as e:
        print(f"Error creating performance comparison plot: {e}")
    
    # 2. Training Progression Plot (if detailed results available)
    try:
        # Load detailed results for training curves
        results_dir = "results/comparison"
        comparison_files = [f for f in os.listdir(results_dir) if f.startswith("coral_gpcm_embedding_comparison")]
        latest_file = sorted(comparison_files)[-1]
        
        with open(os.path.join(results_dir, latest_file), 'r') as f:
            detailed_data = json.load(f)
        
        prog_path = f"results/plots/coral_gpcm_training_progression_{timestamp}.png"
        create_training_progression_plot(detailed_data['detailed_results'], prog_path)
        plots_created.append(prog_path)
    except Exception as e:
        print(f"Error creating training progression plot: {e}")
    
    # 3. Winner Analysis Plot
    try:
        winner_path = f"results/plots/coral_gpcm_winner_analysis_{timestamp}.png"
        create_winner_analysis_plot(df, winner_path)
        plots_created.append(winner_path)
    except Exception as e:
        print(f"Error creating winner analysis plot: {e}")
    
    # Print summary
    print(f"\nüé® VISUALIZATION DASHBOARD COMPLETE!")
    print(f"{'='*60}")
    print(f"üìä Plots created: {len(plots_created)}")
    for plot_path in plots_created:
        print(f"   üìà {os.path.basename(plot_path)}")
    
    print(f"\nüîç QUICK INSIGHTS:")
    print(f"   ‚Ä¢ Total configurations tested: {len(df)}")
    print(f"   ‚Ä¢ Model types: {', '.join(df['model_type'].unique())}")
    print(f"   ‚Ä¢ Embedding strategies: {', '.join(df['embedding_strategy'].unique())}")
    print(f"   ‚Ä¢ Best performer: {df.loc[df['categorical_acc'].idxmax(), 'model_type']} "
          f"{df.loc[df['categorical_acc'].idxmax(), 'embedding_strategy']} "
          f"({df['categorical_acc'].max():.1%})")
    
    return plots_created


if __name__ == "__main__":
    create_comprehensive_dashboard()