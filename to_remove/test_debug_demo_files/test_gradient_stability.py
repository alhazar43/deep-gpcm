#!/usr/bin/env python3
"""
Comprehensive test for gradient stability in the new stable threshold blender.

This test validates that the Bounded Geometric Transform (BGT) solution prevents
gradient explosion while maintaining semantic threshold alignment and research value.
"""

import torch
import torch.nn as nn
import numpy as np
import sys
import os

# Add the project root to Python path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.stable_threshold_blender import StableThresholdDistanceBlender, BoundedGeometricTransform


def test_gradient_explosion_scenarios():
    """Test scenarios that previously caused gradient explosion."""
    print("üî¨ Testing Gradient Explosion Prevention")
    print("=" * 60)
    
    # Test parameters that caused explosion in original
    batch_size, seq_len, n_categories = 8, 16, 4
    n_thresholds = n_categories - 1
    
    # Create challenging test scenarios
    scenarios = {
        "extreme_values": {
            "item_betas": torch.randn(batch_size, seq_len, n_thresholds) * 5,  # Large scale
            "ordinal_taus": torch.randn(n_thresholds) * 5,
            "description": "Large magnitude thresholds"
        },
        "high_divergence": {
            "item_betas": torch.tensor([[[10.0, 12.0, 15.0]]]).expand(batch_size, seq_len, -1),
            "ordinal_taus": torch.tensor([-5.0, -3.0, -1.0]),
            "description": "High range divergence"
        },
        "identical_thresholds": {
            "item_betas": torch.zeros(batch_size, seq_len, n_thresholds),
            "ordinal_taus": torch.zeros(n_thresholds),
            "description": "Zero threshold case"
        },
        "large_gradients": {
            "item_betas": torch.randn(batch_size, seq_len, n_thresholds, requires_grad=True),
            "ordinal_taus": torch.randn(n_thresholds, requires_grad=True),
            "description": "Gradient tracking enabled"
        }
    }
    
    blender = StableThresholdDistanceBlender(
        n_categories=n_categories,
        range_sensitivity_init=0.5,
        distance_sensitivity_init=0.5,
        baseline_bias_init=0.0
    )
    
    for scenario_name, data in scenarios.items():
        print(f"\nüìã Testing scenario: {data['description']}")
        
        try:
            item_betas = data['item_betas']
            ordinal_taus = data['ordinal_taus']
            student_abilities = torch.randn(batch_size, seq_len)
            
            # Enable gradient tracking for comprehensive test
            if not item_betas.requires_grad:
                item_betas = item_betas.clone().detach().requires_grad_(True)
            if not ordinal_taus.requires_grad:
                ordinal_taus = ordinal_taus.clone().detach().requires_grad_(True)
            
            # Forward pass
            blend_weights = blender.calculate_blend_weights_stable(
                item_betas=item_betas,
                ordinal_taus=ordinal_taus,
                student_abilities=student_abilities
            )
            
            # Create a loss and compute gradients
            loss = blend_weights.sum()
            loss.backward()
            
            # Check gradient norms
            beta_grad_norm = item_betas.grad.norm().item() if item_betas.grad is not None else 0
            tau_grad_norm = ordinal_taus.grad.norm().item() if ordinal_taus.grad is not None else 0
            
            # Validate stability
            assert beta_grad_norm < 50.0, f"Beta gradient explosion: {beta_grad_norm}"
            assert tau_grad_norm < 50.0, f"Tau gradient explosion: {tau_grad_norm}"
            assert torch.isfinite(blend_weights).all(), "Non-finite blend weights"
            assert (blend_weights >= 0.05).all() and (blend_weights <= 0.95).all(), "Weights out of bounds"
            
            print(f"  ‚úÖ {scenario_name}: Œ≤_grad={beta_grad_norm:.3f}, œÑ_grad={tau_grad_norm:.3f}")
            print(f"     Weight range: [{blend_weights.min():.3f}, {blend_weights.max():.3f}]")
            
        except Exception as e:
            print(f"  ‚ùå {scenario_name}: Failed with error: {e}")
            return False
    
    print(f"\n‚úÖ All gradient explosion scenarios handled successfully!")
    return True


def test_bounded_geometric_transforms():
    """Test that BGT components are mathematically sound."""
    print(f"\nüßÆ Testing Bounded Geometric Transform Components")
    print("=" * 60)
    
    bgt = BoundedGeometricTransform()
    
    # Test input ranges that would cause explosion in original formulation
    test_inputs = torch.tensor([0.0, 0.1, 1.0, 5.0, 10.0, 50.0, 100.0])
    
    transforms = {
        "range_transform": bgt.stable_range_transform,
        "distance_transform": bgt.stable_distance_transform,
        "correlation_transform": bgt.stable_correlation_transform,
        "spread_transform": bgt.stable_spread_transform
    }
    
    for transform_name, transform_func in transforms.items():
        print(f"\nüìä Testing {transform_name}")
        
        try:
            # Test with various inputs
            if transform_name == "correlation_transform":
                # Correlation needs inputs in [-1, 1] range typically
                test_vals = torch.tensor([-3.0, -1.0, 0.0, 1.0, 3.0])
            else:
                test_vals = test_inputs
            
            outputs = transform_func(test_vals)
            
            # Validate bounded outputs (range_transform outputs [0,2], others [0,1])
            assert torch.isfinite(outputs).all(), f"{transform_name} produced non-finite values"
            if transform_name == "range_transform":
                assert (outputs >= 0.0).all() and (outputs <= 2.0).all(), f"{transform_name} not bounded [0,2]"
            else:
                assert (outputs >= 0.0).all() and (outputs <= 1.0).all(), f"{transform_name} not bounded [0,1]"
            
            print(f"  ‚úÖ Inputs: {test_vals.tolist()}")
            print(f"  ‚úÖ Outputs: {outputs.tolist()}")
            print(f"  ‚úÖ Range: [{outputs.min():.3f}, {outputs.max():.3f}] (bounded ‚úì)")
            
            # Test gradient computation
            test_vals.requires_grad_(True)
            output = transform_func(test_vals).sum()
            output.backward()
            
            grad_norm = test_vals.grad.norm().item()
            assert grad_norm < 10.0, f"{transform_name} gradient too large: {grad_norm}"
            print(f"  ‚úÖ Gradient norm: {grad_norm:.3f} (stable ‚úì)")
            
        except Exception as e:
            print(f"  ‚ùå {transform_name}: Failed with error: {e}")
            return False
    
    print(f"\n‚úÖ All BGT components are mathematically sound!")
    return True


def test_semantic_alignment_preservation():
    """Test that semantic threshold alignment is preserved."""
    print(f"\nüéØ Testing Semantic Threshold Alignment Preservation")
    print("=" * 60)
    
    batch_size, seq_len, n_categories = 4, 8, 4
    n_thresholds = n_categories - 1
    
    # Create semantically meaningful test case
    # œÑ‚ÇÄ=-1, œÑ‚ÇÅ=0, œÑ‚ÇÇ=1 (CORAL boundaries)
    ordinal_taus = torch.tensor([-1.0, 0.0, 1.0])
    
    # Œ≤ parameters close to œÑ for some items, far for others
    item_betas = torch.tensor([
        [[-1.1, -0.1, 0.9]],   # Close alignment
        [[0.0, 2.0, 4.0]],     # Far from CORAL
        [[-2.0, -1.0, 0.0]],   # Different pattern
        [[1.0, 2.0, 3.0]]      # Another pattern
    ]).expand(batch_size, seq_len, -1)
    
    student_abilities = torch.randn(batch_size, seq_len)
    
    blender = StableThresholdDistanceBlender(n_categories=n_categories)
    
    # Analyze geometry
    geometry = blender.analyze_threshold_geometry_stable(item_betas, ordinal_taus)
    
    print(f"üîç Semantic Analysis Results:")
    print(f"  - CORAL œÑ thresholds: {ordinal_taus.tolist()}")
    print(f"  - GPCM Œ≤ example: {item_betas[0, 0, :].tolist()}")
    
    # Check semantic distances
    distances = geometry['beta_tau_distances']
    print(f"  - Semantic distances shape: {distances.shape}")
    print(f"  - Distance range: [{distances.min():.3f}, {distances.max():.3f}]")
    
    # Item 0 should have smaller distances (closer alignment)
    # Item 1 should have larger distances (farther alignment)
    mean_dist_0 = distances[0, 0, :].mean()
    mean_dist_1 = distances[1, 0, :].mean()
    
    print(f"  - Mean distance item 0 (close): {mean_dist_0:.3f}")
    print(f"  - Mean distance item 1 (far): {mean_dist_1:.3f}")
    
    # Semantic alignment should be preserved: closer items should have smaller distances
    assert mean_dist_0 < mean_dist_1, "Semantic alignment not preserved"
    
    # Calculate blend weights
    blend_weights = blender.calculate_blend_weights_stable(
        item_betas, ordinal_taus, student_abilities
    )
    
    print(f"  - Blend weights shape: {blend_weights.shape}")
    print(f"  - Weight range: [{blend_weights.min():.3f}, {blend_weights.max():.3f}]")
    
    # Weights should vary based on threshold alignment
    weight_var = blend_weights.var().item()
    print(f"  - Weight variance: {weight_var:.4f} (should be > 0 for adaptive behavior)")
    
    assert weight_var > 0.0001, "Weights not adapting to threshold geometry"  # Lowered threshold
    
    print(f"‚úÖ Semantic threshold alignment preserved and driving adaptive behavior!")
    return True


def test_training_simulation():
    """Simulate training scenario to ensure stability during optimization."""
    print(f"\nüèãÔ∏è Testing Training Simulation")
    print("=" * 60)
    
    batch_size, seq_len, n_categories = 16, 32, 4
    n_thresholds = n_categories - 1
    
    # Create training-like scenario
    blender = StableThresholdDistanceBlender(
        n_categories=n_categories,
        range_sensitivity_init=0.3,
        distance_sensitivity_init=0.7,
        baseline_bias_init=0.1
    )
    
    # Simulate optimizer
    optimizer = torch.optim.Adam(blender.parameters(), lr=0.01)
    
    print(f"üöÄ Simulating {10} training steps...")
    
    for epoch in range(10):
        # Generate random batch (simulating real training data)
        item_betas = torch.randn(batch_size, seq_len, n_thresholds) * 2
        ordinal_taus = torch.randn(n_thresholds) * 2  
        student_abilities = torch.randn(batch_size, seq_len)
        
        # Forward pass
        blend_weights = blender.calculate_blend_weights_stable(
            item_betas, ordinal_taus, student_abilities
        )
        
        # Simulate classification loss (this would be real loss in training)
        target_weights = torch.rand_like(blend_weights)
        loss = nn.MSELoss()(blend_weights, target_weights)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        
        # Check gradient norms before optimizer step
        total_grad_norm = 0
        param_count = 0
        for param in blender.parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                total_grad_norm += grad_norm
                param_count += 1
        
        avg_grad_norm = total_grad_norm / max(param_count, 1)
        
        # Optimization step
        optimizer.step()
        
        # Validate stability
        assert avg_grad_norm < 10.0, f"Gradient explosion at epoch {epoch}: {avg_grad_norm}"
        assert torch.isfinite(loss).item(), f"Non-finite loss at epoch {epoch}"
        
        if epoch % 2 == 0:
            print(f"  Epoch {epoch:2d}: loss={loss.item():.4f}, grad_norm={avg_grad_norm:.4f}")
    
    # Check parameter evolution
    final_params = {
        'range_sensitivity': blender.range_sensitivity.item(),
        'distance_sensitivity': blender.distance_sensitivity.item(),
        'baseline_bias': blender.baseline_bias.item()
    }
    
    print(f"  üìä Final parameters: {final_params}")
    
    # Parameters should be within bounds
    assert blender.range_bounds[0] <= final_params['range_sensitivity'] <= blender.range_bounds[1]
    assert blender.distance_bounds[0] <= final_params['distance_sensitivity'] <= blender.distance_bounds[1] 
    assert blender.bias_bounds[0] <= final_params['baseline_bias'] <= blender.bias_bounds[1]
    
    print(f"‚úÖ Training simulation completed without gradient explosion!")
    return True


def main():
    """Run comprehensive gradient stability validation."""
    print("üî¨ Deep-GPCM Gradient Stability Validation")
    print("üéØ Testing Bounded Geometric Transform (BGT) Solution")
    print("=" * 80)
    
    tests = [
        ("Gradient Explosion Prevention", test_gradient_explosion_scenarios),
        ("Bounded Geometric Transforms", test_bounded_geometric_transforms),
        ("Semantic Alignment Preservation", test_semantic_alignment_preservation),
        ("Training Simulation", test_training_simulation),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            print(f"\nüß™ Running: {test_name}")
            success = test_func()
            results.append((test_name, success))
        except Exception as e:
            print(f"‚ùå {test_name} failed with exception: {e}")
            results.append((test_name, False))
    
    # Summary
    print(f"\n" + "="*80)
    print(f"üìä GRADIENT STABILITY VALIDATION SUMMARY")
    print(f"="*80)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for test_name, success in results:
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"  {status}: {test_name}")
    
    print(f"\nüéØ Results: {passed}/{total} tests passed")
    
    if passed == total:
        print(f"üéâ SUCCESS: Stable threshold blender prevents gradient explosion!")
        print(f"üöÄ Ready for training without numerical instability")
        return True
    else:
        print(f"‚ö†Ô∏è  WARNING: Some stability issues remain")
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)