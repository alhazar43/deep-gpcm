{
  "timestamp": "2025-07-28T07:19:49.408617",
  "model_path": "save_models/best_baseline_synthetic_OC.pth",
  "config": {
    "model_type": "baseline",
    "n_questions": 30,
    "n_cats": 4,
    "dataset": "synthetic_OC",
    "fold": 4
  },
  "dataset": "synthetic_OC",
  "evaluation_config": {
    "batch_size": 32,
    "device": "cuda"
  },
  "training_metrics": {
    "categorical_accuracy": 0.7138429880142212,
    "ordinal_accuracy": 0.8688016533851624,
    "quadratic_weighted_kappa": 0.680661944356597,
    "mean_absolute_error": 0.4762396812438965,
    "train_accuracy": 0.7277719665271967,
    "train_loss": 1.0094040989875794,
    "best_epoch": 49,
    "total_epochs": 50,
    "parameters": 134055,
    "model_type": "BaselineGPCM"
  },
  "evaluation_results": {
    "argmax": {
      "method": "argmax",
      "categorical_accuracy": 0.716286301612854,
      "ordinal_accuracy": 0.8760373592376709,
      "mean_absolute_error": 0.4621369242668152,
      "quadratic_weighted_kappa": 0.7078078148290843,
      "prediction_consistency": 0.716286301612854,
      "ordinal_ranking": 0.7596325091099824,
      "distribution_consistency": 0.8265716031085529,
      "cat_0_acc": 0.9517857432365417,
      "cat_1_acc": 0.0533333346247673,
      "cat_2_acc": 0.0803571417927742,
      "cat_3_acc": 0.7938718795776367
    },
    "cumulative": {
      "method": "cumulative",
      "categorical_accuracy": 0.7126556038856506,
      "ordinal_accuracy": 0.8843361139297485,
      "mean_absolute_error": 0.45072615146636963,
      "quadratic_weighted_kappa": 0.7174426660508411,
      "prediction_consistency": 0.24273858964443207,
      "ordinal_ranking": 0.7596325091099824,
      "distribution_consistency": 0.8265716031085529,
      "cat_0_acc": 0.9392856955528259,
      "cat_1_acc": 0.08888889104127884,
      "cat_2_acc": 0.1517857164144516,
      "cat_3_acc": 0.7465181350708008
    },
    "expected": {
      "method": "expected",
      "categorical_accuracy": 0.7136929631233215,
      "ordinal_accuracy": 0.8895228505134583,
      "mean_absolute_error": 0.44087135791778564,
      "quadratic_weighted_kappa": 0.7222070451116824,
      "prediction_consistency": 0.7136929631233215,
      "ordinal_ranking": 0.7596325091099824,
      "distribution_consistency": 0.8265716031085529,
      "cat_0_acc": 0.9303571581840515,
      "cat_1_acc": 0.12888889014720917,
      "cat_2_acc": 0.2142857164144516,
      "cat_3_acc": 0.7158774137496948
    },
    "improvement_analysis": {
      "categorical_accuracy_improvement": -0.003630697727203369,
      "categorical_accuracy_improvement_pct": -0.5068780066054825,
      "prediction_consistency_improvement": -0.47354771196842194,
      "prediction_consistency_improvement_pct": -66.11151307823977,
      "ordinal_accuracy_improvement": 0.008298754692077637,
      "mae_improvement": 0.011410772800445557
    },
    "performance": {
      "avg_inference_time_ms": 136.49654388427734,
      "total_samples": 1928,
      "samples_per_second": 7062.449880176347
    },
    "confusion_matrix": [
      [
        1066,
        3,
        6,
        45
      ],
      [
        155,
        12,
        6,
        52
      ],
      [
        67,
        17,
        18,
        122
      ],
      [
        60,
        9,
        5,
        285
      ]
    ]
  }
}